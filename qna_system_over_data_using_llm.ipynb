{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QnA System Over Structured Data using LLM\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Latar belakang proyek ini berasal dari kebutuhan akan solusi yang lebih efisien dan efektif dalam menjawab pertanyaan yang berkaitan dengan data terstruktur. Dalam lingkungan bisnis yang semakin kompleks, akses cepat dan akurat terhadap informasi yang tersembunyi dalam data terstruktur menjadi krusial. Namun, pengolahan data semacam ini dapat menjadi rumit dan memerlukan upaya manual yang signifikan. Oleh karena itu, mengintegrasikan kecerdasan buatan, seperti Large Language Model (LLM), dengan data terstruktur dapat membawa solusi yang inovatif untuk meningkatkan efisiensi dan kualitas dalam menjawab pertanyaan-pertanyaan tersebut.\n",
    "\n",
    "> ðŸ”Ž Tujuan utama dari proyek ini adalah mengembangkan sebuah sistem pertanyaan dan jawaban yang menggabungkan kekuatan Large Language Model (LLM) dengan informasi terstruktur dari data dalam format terstruktur, seperti file CSV atau SQL. \n",
    "\n",
    "Dengan memadukan potensi LLM dalam memahami bahasa alami dengan informasi terstruktur yang ada dalam dataset, proyek ini bertujuan untuk menciptakan solusi yang dapat memberikan jawaban yang lebih kontekstual dan akurat. Selain itu, proyek ini juga bermaksud untuk mengeksplorasi cara-cara mengoptimalkan interaksi antara data teks dan terstruktur, dengan harapan dapat memberikan panduan yang berguna bagi pengembangan solusi serupa di masa depan. Melalui kombinasi ini, proyek ini diharapkan mampu menyediakan alat yang bermanfaat untuk meningkatkan efisiensi, produktivitas, dan pengambilan keputusan dalam berbagai konteks bisnis yang mengandalkan analisis data terstruktur.\n",
    "\n",
    "<img title=\"karate cat\" src=\"assets/GIF_Generative-ChatGPT.gif\" width = 60%>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoritical Basis\n",
    "\n",
    "### Generative AI\n",
    "\n",
    "<img title=\"karate cat\" src=\"assets/AI-GIF-Generator-min.gif\" width = 60%>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <p>\n",
    "    <li>Generative AI adalah subbidang kecerdasan buatan yang berfokus pada pengembangan model yang mampu menghasilkan data baru yang sebelumnya tidak ada.</li>\n",
    "    <li>Model generatif dapat menciptakan teks, gambar, suara, dan data lainnya yang serupa dengan data yang digunakan untuk melatih model.</li>\n",
    "    <li>Model generative AI, seperti Large Language Models (LLM), adalah contoh utama dari jenis ini. Model-model ini dilatih pada jumlah besar data dan dapat menghasilkan teks, gambar, suara, dan bahkan video yang seolah-olah dibuat oleh manusia.</li>\n",
    "    <hr><br>\n",
    "    ðŸ“Œ <b>Pada intinya, generative AI memiliki kemampuan untuk \"mengerti\" pola dan struktur dari data pelatihan dan menggunakan pemahaman ini untuk membuat data baru yang serupa. </b>\n",
    "    </p>\n",
    "</div> \n",
    "\n",
    "Konsep generative AI memainkan peran sentral dalam proyek ini yang berfokus pada pengembangan sistem Pertanyaan dan Jawaban (QA) berbasis Large Language Model (LLM) menggunakan data terstruktur. \n",
    "\n",
    "> ðŸ”Ž Generative AI merupakan paradigma yang memungkinkan penciptaan data baru yang otentik, dengan model yang mampu menghasilkan informasi yang sebelumnya tidak ada berdasarkan pemahaman pola dari data pelatihan. \n",
    "\n",
    "Dalam konteks proyek ini, generative AI membuka pintu untuk **menghasilkan jawaban yang kontekstual** dan relevan dalam sistem QA. Dengan memanfaatkan Large Language Model, yang pada dasarnya merupakan jenis generative AI, sistem ini dapat menghasilkan jawaban berdasarkan pemahaman bahasa alami serta informasi terstruktur yang ditemukan dalam data yang disajikan dalam format terstruktur. Integrasi generative AI dalam solusi QA ini mampu menghasilkan respons yang lebih kreatif dan kontekstual, serta memberikan solusi yang potensial dalam meningkatkan efektivitas komunikasi dan analisis dalam berbagai konteks bisnis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Language Models\n",
    "\n",
    "LLM adalah aplikasi khusus dari Generative AI yang difokuskan pada generasi teks. Mereka menggunakan teknik generatif AI, seperti pemodelan probabilitas dan prediksi urutan, untuk menghasilkan teks yang menyerupai manusia. Dengan memodelkan sifat statistik bahasa, LLM dapat menghasilkan teks yang kohesif, relevan, dan sering kali sulit dibedakan dari teks yang ditulis oleh manusia.\n",
    "\n",
    "Istilah \"Large\" dalam konteks Large Language Models (LLM) merujuk pada dua aspek:\n",
    "\n",
    "**1. Dataset pelatihan besar**\n",
    "\n",
    " - LLM umumnya dilatih pada jumlah besar data teks untuk menangkap pola dan struktur statistik yang ada dalam bahasa.\n",
    " - Dataset pelatihan dapat terdiri dari berbagai sumber seperti buku, artikel, situs web, dan korpus teks lainnya, yang memberikan beragam pola dan konteks linguistik.\n",
    " - Dengan menggunakan dataset pelatihan yang besar, LLM memiliki kesempatan untuk belajar dari sejumlah besar informasi dan meningkatkan kemampuan pemodelan bahasanya.\n",
    "    \n",
    "**2. Jumlah parameter besar**\n",
    "\n",
    " - LLM ditandai dengan jumlah parameter yang signifikan, yaitu variabel yang dapat dipelajari yang menentukan perilaku model.\n",
    " - Jumlah parameter dalam LLM dapat berkisar dari jutaan hingga miliaran, tergantung pada ukuran dan kompleksitas model.\n",
    " - Meningkatkan jumlah parameter memungkinkan LLM untuk menangkap pola bahasa yang lebih rumit dan menghasilkan teks yang lebih kohesif dan kontekstual.\n",
    " - Model dengan jumlah parameter yang lebih besar dapat menangani berbagai tugas bahasa dan menunjukkan kemampuan generasi bahasa yang lebih unggul.\n",
    "\n",
    "\n",
    "LLM adalah model canggih yang dirancang untuk berbagai tugas yang terkait dengan teks. Tugas-tugas ini meliputi:\n",
    "\n",
    "<img title=\"llm problem\" src=\"assets/llm_problem.png\">\n",
    "\n",
    "1. **Klasifikasi Teks**: LLM dapat diadaptasi untuk mengklasifikasikan teks ke dalam berbagai kategori atau label yang telah ditentukan sebelumnya. Melalui pelatihan dengan data yang telah diberi label, mereka belajar untuk mengidentifikasi pola-pola yang mengindikasikan kelas-kelas tertentu. Contohnya termasuk mengklasifikasikan email sebagai spam atau bukan, menganalisis sentimen (positif, negatif, netral) dalam teks, dan mengategorikan artikel berita berdasarkan topiknya.\n",
    "\n",
    "2. **Pertanyaan dan Jawaban**: LLM dapat memahami pertanyaan dan memberikan jawaban yang akurat berdasarkan konteks atau basis pengetahuan yang diberikan. Melalui pelatihan dengan pasangan pertanyaan dan jawaban, mereka dapat menghasilkan respons yang relevan. Mereka digunakan dalam chatbot, asisten virtual, dan mesin pencari.\n",
    "\n",
    "3. **Ringkasan Dokumen**: LLM mampu merangkum dokumen-dokumen panjang dengan mengidentifikasi informasi-informasi penting. Melalui pelatihan dengan pasangan dokumen dan ringkasannya, mereka belajar untuk membuat ringkasan yang koheren dan singkat. Ini berguna dalam pengambilan informasi, analisis konten, dan kompresi data.\n",
    "\n",
    "4. **Penghasilan Teks**: LLM memiliki kemampuan untuk menghasilkan teks yang menyerupai bahasa manusia untuk berbagai tujuan. Mereka memanfaatkan pemahaman dan kemampuan generasi bahasa mereka untuk menghasilkan teks yang koheren dan sesuai konteks. Mereka dapat disesuaikan untuk membuat cerita, puisi, deskripsi produk, dan lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM Development vs. Traditional Development\n",
    "\n",
    "| Pengembangan LLM (menggunakan API yang telah dipre-train) | Pengembangan ML Tradisional |\n",
    "| ----------- | ----------- |\n",
    "| Tidak memerlukan keahlian ML      | Memerlukan keahlian ML       |\n",
    "| Tidak memerlukan contoh pelatihan   | Memerlukan contoh pelatihan       |\n",
    "| Tidak perlu melatih model | Perlu melatih model|\n",
    "| Memikirkan desain permintaan | Memikirkan cara meminimalkan fungsi kerugian|\n",
    "\n",
    "\n",
    "#### LLM usage in various business contexts\n",
    "\n",
    "**1. Customer Support and Chatbots:**\n",
    "   - Showcasing a chatbot powered by an LLM that can handle customer inquiries, provide product recommendations, and assist with common support issues.\n",
    "   - Demonstrating the chatbot's ability to understand and respond to user queries, maintaining a natural and conversational interaction.\n",
    "\n",
    "**2. Content Generation and Marketing:**\n",
    "   - Demonstrating how an LLM can generate engaging and personalized content for marketing campaigns, social media posts, or email newsletters.\n",
    "   - Showcasing the LLM's ability to generate content that aligns with the brand's voice and resonates with the target audience.\n",
    "\n",
    "**3. Data Analysis and Insights:**\n",
    "   - Demonstrating how an LLM can analyze large volumes of customer feedback, reviews, or survey responses to extract valuable insights.\n",
    "   - Showcasing the LLM's ability to identify trends, sentiments, and key topics within the data, enabling data-driven decision-making.\n",
    "\n",
    "**4. Document Processing and Automation:**\n",
    "   - Demonstrating how an LLM can automate the processing of documents, such as contract analysis, by extracting relevant information, identifying clauses, or generating summaries.\n",
    "   - Showcasing the time-saving and accuracy improvements achieved through LLM-powered document automation.\n",
    "\n",
    "**5. Language Translation and Localization:**\n",
    "   - Demonstrating an LLM's ability to perform accurate language translation across multiple languages.\n",
    "   - Showcasing how the LLM can handle nuances, idioms, and context-specific translations, enabling effective communication in global markets.\n",
    "\n",
    "**6. Data-driven Decision-making:**\n",
    "   - Demonstrating how an LLM can analyze market trends, customer behavior, or social media data to provide insights for strategic decision-making.\n",
    "   - Showcasing the LLM's ability to identify patterns, correlations, or emerging topics within the data, facilitating informed business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <p>\n",
    "    <b>Large Language Model (LLM)</b>\n",
    "    <li>Large Language Models (LLMs) adalah model bahasa yang diperluas, seperti GPT (Generative Pre-trained Transformer) dan BERT (Bidirectional Encoder Representations from Transformers).</li>\n",
    "    <li>LLMs dapat memahami dan menghasilkan teks yang kompleks dengan mempelajari pola bahasa dari data pelatihan yang besar dan beragam.</li>\n",
    "    <li>Mereka menggunakan arsitektur Transformer, yang memiliki kemampuan untuk memahami konteks dalam teks dengan cara yang lebih baik dibandingkan arsitektur sebelumnya.</li>\n",
    "    <hr><br>\n",
    "    <b>Understanding Transformer</b>\n",
    "    <li>Transformer adalah arsitektur model yang mendasari banyaknya kemajuan dalam bidang pemrosesan bahasa alami.</li>\n",
    "    <li>Ini mengatasi masalah dependensi jarak jauh dalam bahasa dengan menggunakan mekanisme self-attention, yang memungkinkan model untuk mengaitkan kata-kata yang berjauhan dalam teks.</li>\n",
    "    <li>Transformer terdiri dari encoder dan decoder, dengan encoder bertanggung jawab untuk memahami teks asli dan decoder menghasilkan teks hasil terjemahan atau generasi.</li>\n",
    "    <hr><br>\n",
    "    <b>Popular Large Language Models</b>\n",
    "    <li>GPT-3 (Generative Pre-trained Transformer 3) adalah salah satu LLM paling terkenal yang dikembangkan oleh OpenAI. Ini memiliki 175 miliar parameter dan mampu melakukan berbagai tugas bahasa alami.</li>\n",
    "    <li>BERT (Bidirectional Encoder Representations from Transformers) adalah LLM yang fokus pada pemahaman konteks dengan memeriksa konteks sebelum dan sesudah setiap kata dalam kalimat.</li>\n",
    "    <li>T5 (Text-to-Text Transfer Transformer) adalah LLM yang mengusulkan pendekatan \"teks-ke-teks\" untuk berbagai tugas bahasa, seperti menerjemahkan, menyusun, dan banyak lagi.</li>\n",
    "    <hr><br>\n",
    "    ðŸ“Œ <b>Konsep LLMs adalah inti dalam proyek ini, dengan menggabungkan informasi dari data terstruktur, seperti file CSV, dengan pemahaman LLM tentang bahasa, sistem QA yang dihasilkan memberikan jawaban lebih kontekstual dan akurat.</b>\n",
    "    </p>\n",
    "</div> \n",
    "\n",
    "\n",
    "\n",
    "    <b></b>\n",
    "    <li></li>\n",
    "    <li></li>\n",
    "    <li></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html) merupakan alat yang relevan dalam konteks proyek ini yang fokus pada pengembangan sistem Pertanyaan dan Jawaban (QA) menggunakan Large Language Model (LLM) dan data terstruktur. LangChain adalah *framework* Python yang dirancang khusus untuk mengintegrasikan informasi dari data terstruktur, seperti file CSV, dengan kekuatan pemrosesan bahasa alami yang dimiliki oleh LLM. Dengan menggunakan LangChain, proyek ini memiliki kemampuan untuk menghubungkan antara konteks terstruktur dalam data dengan pemahaman bahasa alami, sehingga memungkinkan sistem QA untuk memberikan jawaban yang lebih kontekstual dan akurat. Melalui penggunaan pustaka ini, integrasi antara data terstruktur dan LLM dapat dilakukan dengan lebih efisien dan efektif, membantu menciptakan solusi QA yang lebih adaptif dan canggih."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Set-up\n",
    "\n",
    "\n",
    "Penggunaan LangChain biasanya memerlukan integrasi dengan satu atau lebih penyedia model, penyimpanan data, API, dan sebagainya. Pada contoh ini, kami akan menggunakan API model dari OpenAI.\n",
    "\n",
    "#### Mengatur Key API dan File `.env`\n",
    "\n",
    "Akses ke API memerlukan Key API, yang dapat Anda peroleh dengan membuat akun dan mengunjungi halaman ini. Ketika mengatur Key API dan menggunakan file .env dalam proyek Python Anda, ikuti langkah umum berikut:\n",
    "\n",
    "1. **Dapatkan Key API**: Jika Anda bekerja dengan API atau layanan eksternal yang memerlukan Key API, Anda perlu memperolehnya dari penyedia. Ini biasanya melibatkan pendaftaran akun dan pembuatan Key API khusus untuk proyek Anda.\n",
    "\n",
    "2. **Buat file .env**: Di direktori proyek Anda, buat berkas baru dan beri nama \".env\". Berkas ini akan menyimpan kunci API dan informasi sensitif lainnya secara aman.\n",
    "\n",
    "3. **Simpan kunci API di .env**: Buka berkas .env dengan editor teks dan tambahkan baris untuk menyimpan kunci API Anda. Formatnya harus `OPENAI_API_KEY=key_api_anda`, di mana \"OPENAI_API_KEY\" adalah nama variabel dan \"key_api_anda\" adalah nilai sebenarnya dari key API Anda. Pastikan untuk tidak menyertakan tanda kutip atau spasi di sekitar nilai tersebut.\n",
    "\n",
    "4. **Muat variabel lingkungan**: Dalam kode Python Anda, Anda perlu memuat variabel lingkungan dari berkas .env sebelum mengaksesnya. Impor modul dotenv dan tambahkan kode berikut di awal skrip Anda:\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Muat variabel lingkungan dari berkas .env\n",
    "load_dotenv()\n",
    "```\n",
    "\n",
    "> `dotenv` adalah pustaka Python yang populer yang menyederhanakan proses memuat variabel lingkungan dari berkas .env ke aplikasi Python Anda. Ini memungkinkan Anda menyimpan variabel konfigurasi secara terpisah dari kode Anda, sehingga lebih mudah mengelola informasi sensitif seperti kunci API, kredensial basis data, atau pengaturan khusus lingkungan lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Homestead Eats.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is a good name for a brand that makes local burger?\"\n",
    "print(llm.predict(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mentaipang.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Nama yang bagus untuk brand yang membuat pisang goreng mentai?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
